{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZMbpw2pORMl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -qU langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oePLbclDOjki"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain-community pypdf\n",
        "!pip install -qU langchain-huggingface\n",
        "!pip install -U langchain-google-genai\n",
        "!pip install \"unstructured[image]\"\n",
        "!pip install pillow opencv-python\n",
        "!pip install tqdm\n",
        "!pip install ddgs\n",
        "!pip install -U langchain langchain-community langchain-core\n",
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDP2loMPQ07H"
      },
      "source": [
        "**LLM Model Instantiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI3d6TXBPL5L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings # New import\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPlcyvDL7b5_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -qU langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE3Pp33_7WZG"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "cloud_client = chromadb.CloudClient(\n",
        "    api_key=\"\",\n",
        "    tenant=\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49pxfS3q7oRU"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_function = HuggingFaceEmbeddings(model_name=\"minishlab/potion-base-8M\")\n",
        "\n",
        "vector_store = Chroma(\n",
        "    client=cloud_client,\n",
        "    collection_name=\"rest\", # Replace with your actual collection name\n",
        "    embedding_function=embedding_function # Added embedding function\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U99QS0FnPNgR"
      },
      "source": [
        "# Tools for R&A Orchestrator Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWNDeiA1Pk6e"
      },
      "source": [
        "Context Retrieval Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6hBhOQKPWNT"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from ddgs import DDGS\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve_context(query: str, k: int = 3):\n",
        "    \"\"\"Retrieve top-k relevant contexts from uploaded research papers.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=k)\n",
        "    serialized = \"\\n\\n---\\n\\n\".join(\n",
        "        (\n",
        "            f\"ğŸ“„ Source: {doc.metadata.get('title', 'Unknown')}\\n\"\n",
        "            f\"Similarity: {doc.metadata.get('score', 'N/A')}\\n\"\n",
        "            f\"{doc.page_content}\"\n",
        "        )\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUOJe3gNQDB3"
      },
      "source": [
        "Summarizer Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvxYxe6UQPc5"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool(\"chroma_pdf_summarizer\", return_direct=True)\n",
        "def chroma_pdf_summarizer(pdf_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Summarizes an already-embedded research paper from ChromaDB.\n",
        "    Allows partial match, file name, or full path.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"ğŸ“š Searching ChromaDB for embedded content matching: {pdf_name}\")\n",
        "\n",
        "    vectorstore = vector_store\n",
        "\n",
        "    # Pull all docs + metadata (Chroma does NOT support regex or partial filter)\n",
        "    raw = vectorstore.get()\n",
        "\n",
        "    documents = raw.get(\"documents\", [])\n",
        "    metadatas = raw.get(\"metadatas\", [])\n",
        "\n",
        "    if not documents:\n",
        "        return \"âš ï¸ Vector store is empty. Add data first.\"\n",
        "\n",
        "    # --- MATCH BY: partial filename, full filename, or full path ---\n",
        "    matched_docs = []\n",
        "    matched_sources = set()\n",
        "\n",
        "    for doc, meta in zip(documents, metadatas):\n",
        "        source_meta = meta.get(\"source\", \"\").lower()\n",
        "        if pdf_name.lower() in source_meta:      # partial substring match\n",
        "            matched_docs.append(doc)\n",
        "            matched_sources.add(meta.get(\"source\", \"Unknown\"))\n",
        "\n",
        "    if not matched_docs:\n",
        "        return (\n",
        "            f\"âš ï¸ No data found for '{pdf_name}'.\\n\"\n",
        "            \"ğŸ’¡ Tip: Try passing part of the filename instead of the full path.\\n\"\n",
        "        )\n",
        "\n",
        "    print(f\"ğŸ§© Matched {len(matched_docs)} chunks from:\")\n",
        "    for src in matched_sources:\n",
        "        print(\"   -\", src)\n",
        "\n",
        "    combined_text = \"\\n\".join(matched_docs)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a professional AI research summarizer.\n",
        "Summarize the following research paper content into structured sections:\n",
        "- Title\n",
        "- Abstract\n",
        "- Introduction\n",
        "- Methodology\n",
        "- Results / Findings\n",
        "- Conclusion\n",
        "\n",
        "Return clean JSON (no markdown).\n",
        "Content:\n",
        "{combined_text}\n",
        "\"\"\"\n",
        "\n",
        "    print(\"ğŸ§  Generating structured summary using LLM...\")\n",
        "    response = model.invoke(prompt)\n",
        "\n",
        "    print(\"âœ… Summary generation complete.\")\n",
        "    return response.content.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_aavFueUoIc"
      },
      "source": [
        "Citations Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "MTlfjpPjXMiW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from pypdf import PdfReader\n",
        "\n",
        "def extract_citations_from_pdf(pdf_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Pure Python function that extracts:\n",
        "    - inline citations\n",
        "    - reference entries\n",
        "    - DOIs\n",
        "    \"\"\"\n",
        "\n",
        "    reader = PdfReader(pdf_path)\n",
        "    full_text = \"\"\n",
        "\n",
        "    # Extract all text\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text() or \"\"\n",
        "        full_text += page_text + \"\\n\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1ï¸âƒ£ EXTRACT INLINE CITATIONS\n",
        "    # -----------------------------\n",
        "\n",
        "    inline_patterns = [\n",
        "        r\"\\(([^()]+?,\\s?\\d{4}[a-z]?)\\)\",        # (Smith, 2020)\n",
        "        r\"[A-Z][A-Za-z]+ et al\\.,?\\s?\\d{4}\",    # Smith et al., 2021\n",
        "        r\"[A-Z][A-Za-z]+ and [A-Z][A-Za-z]+,?\\s?\\d{4}\",  # Smith and John, 2019\n",
        "        r\"\\[\\d{1,3}\\]\"                           # [1], [12], etc.\n",
        "    ]\n",
        "\n",
        "    inline_citations = set()\n",
        "    for pattern in inline_patterns:\n",
        "        found = re.findall(pattern, full_text)\n",
        "        for item in found:\n",
        "            inline_citations.add(item.strip())\n",
        "\n",
        "    inline_citations = list(inline_citations)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2ï¸âƒ£ EXTRACT REFERENCE SECTION\n",
        "    # -----------------------------\n",
        "\n",
        "    # Locate \"References\" or \"Bibliography\"\n",
        "    match = re.search(r\"(References|Bibliography)(.*)\", full_text, re.S | re.I)\n",
        "    if match:\n",
        "        ref_section = match.group(2)\n",
        "    else:\n",
        "        ref_section = full_text  # fallback\n",
        "\n",
        "    # Split into entries (numbered, bullet, dash)\n",
        "    ref_entries = re.split(\n",
        "        r\"\\n\\d{1,3}\\.\\s|\\n\\[\\d{1,3}\\]\\s|\\nâ€¢\\s|\\n-\\s\",\n",
        "        ref_section\n",
        "    )\n",
        "\n",
        "    # Clean entries\n",
        "    ref_entries = [\n",
        "        entry.strip()\n",
        "        for entry in ref_entries\n",
        "        if len(entry.strip()) > 20\n",
        "    ]\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3ï¸âƒ£ EXTRACT DOIs\n",
        "    # -----------------------------\n",
        "\n",
        "    doi_pattern = r\"(10\\.\\d{4,9}/[-._;()/:A-Za-z0-9]+)\"\n",
        "    dois = list(set(re.findall(doi_pattern, full_text)))\n",
        "\n",
        "    # -----------------------------\n",
        "    # RETURN STRUCTURED RESULT\n",
        "    # -----------------------------\n",
        "\n",
        "    return {\n",
        "        \"inline_citations\": inline_citations,\n",
        "        \"reference_entries\": ref_entries,\n",
        "        \"dois\": dois\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "VHknl-JzXMqZ"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool(\"extract_references_only\", return_direct=True)\n",
        "def extract_references_only(pdf_path: str) -> list:\n",
        "    \"\"\"\n",
        "    Extract only the reference entries from a PDF using the internal parser.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the research paper PDF.\n",
        "\n",
        "    Returns:\n",
        "        list: Clean list of reference entries.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = extract_citations_from_pdf(pdf_path)\n",
        "\n",
        "        reference_list = result.get(\"reference_entries\", [])\n",
        "\n",
        "        # Make list pretty and safe\n",
        "        clean_list = [\n",
        "            ref.replace(\"\\n\", \" \").strip()\n",
        "            for ref in reference_list\n",
        "            if len(ref.strip()) > 5\n",
        "        ]\n",
        "\n",
        "        return clean_list\n",
        "\n",
        "    except Exception as e:\n",
        "        return {f\"Error extracting references: {str(e)}\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVPCHy4qQQCI"
      },
      "source": [
        "Save Summary to Docx File Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDdoDgci7EL9"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from docx import Document\n",
        "from docx.shared import Pt, Inches\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "@tool(\"summary_to_docx\", return_direct=True)\n",
        "def summary_to_docx(summary_text: str, file_name: str = \"Research_Summary.docx\") -> str:\n",
        "    \"\"\"\n",
        "    Takes a structured summary text and stores it beautifully in a formatted DOCX file.\n",
        "    Input:\n",
        "        - summary_text: The summary content (JSON or formatted text)\n",
        "        - file_name: Optional name for the .docx file (default = Research_Summary.docx)\n",
        "    Output:\n",
        "        - Message containing download instructions and file path\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a new Word document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add a title\n",
        "    doc.add_heading(\"ğŸ“˜ Research Paper Summary\", level=0)\n",
        "\n",
        "    # Add timestamp\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "    doc.add_paragraph(f\"Generated on: {now}\\n\")\n",
        "\n",
        "    # Split summary intelligently (works if itâ€™s JSON or plain text)\n",
        "    sections = []\n",
        "    try:\n",
        "        import json\n",
        "        parsed = json.loads(summary_text)\n",
        "        for key, value in parsed.items():\n",
        "            sections.append((key.title(), value))\n",
        "    except Exception:\n",
        "        # fallback â€” split by section headers\n",
        "        raw_sections = summary_text.split(\"\\n\")\n",
        "        for line in raw_sections:\n",
        "            if \":\" in line:\n",
        "                parts = line.split(\":\", 1)\n",
        "                sections.append((parts[0].strip().title(), parts[1].strip()))\n",
        "\n",
        "    # Format and write each section\n",
        "    for header, body in sections:\n",
        "        doc.add_heading(header, level=1)\n",
        "        para = doc.add_paragraph(body)\n",
        "        para_format = para.paragraph_format\n",
        "        para_format.space_after = Pt(10)\n",
        "        para_format.line_spacing = 1.5\n",
        "\n",
        "    # Save file to local path\n",
        "    output_dir = \"/content/Summaries\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = os.path.join(output_dir, file_name)\n",
        "    doc.save(output_path)\n",
        "\n",
        "    return f\"âœ… Summary successfully saved as DOCX.\\nğŸ“„ File path: {output_path}\\nYou can now download and share this document.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rmhbwBP8_3i"
      },
      "source": [
        "## R&A Orchestrator Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "jtlHC0D1SEhR"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_core.language_models.chat_models import BaseChatModel\n",
        "\n",
        "\n",
        "tools = [summary_to_docx,chroma_pdf_summarizer,retrieve_context,extract_references_only]\n",
        "prompt = (\n",
        "          \"\"\"\n",
        "              You are an Research and Analysis Orchestrator Agent. Ask the user to tell what he want to do:\n",
        "              If he want to create a summary of the provided Data -> call the chroma_pdf_summarizer tool\n",
        "              or If he want to do QnA Research which is RAG Based -> call the retrieve_context tool\n",
        "\n",
        "              Then if he got the summary , ask if he want to save the summary to docx, if yes then call the summary_to_docx tool.\n",
        "              If user want to extract the citations, ask him to provide actual path, which is input to the tool -> extract_references_only\n",
        "              like whatever the path is forexample user says path is \"/content/Paper45\" then call tool as extract_references_only(/content/paper45)\n",
        "\n",
        "\n",
        "          \"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "orchestrator  = create_agent(model, tools, system_prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2UKB8Vv_M6U",
        "outputId": "9007dc4e-4159-4a8e-f754-64c80a55c5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§  Interactive Research System Ready!\n",
            "Type 'exit' to stop.\n",
            "\n",
            "You: hi \n",
            "\n",
            "AI: Hi there! How can I help you today? Are you looking to create a summary of a document, conduct research with QnA, or extract citations? \n",
            "\n",
            "You: extract citations\n",
            "\n",
            "AI: Great! Please provide the actual path to the document you want to extract citations from. For example, you can say \"/content/my_research_paper\". \n",
            "\n",
            "You: /content/Paper_86-Cardio_Edge_Hardware_Software_Co_design_Implementation.pdf\n",
            "\n",
            "AI: [\"WHO, â€œCardiovascular diseases (cvds),â€ accessed on 19 Feb, 2025. [Online]. Available: https://www.who.int/en/news-room/fact-sheets/de tail/cardiovascular-diseases-(cvds)\", \"J. M. Bote, J. Recas, F. Rinc Â´on, D. Atienza, and R. Hermida, â€œA mod- ular low-complexity ecg delineation algorithm for real-time embedded systems,â€IEEE Journal of Biomedical and Health Informatics, vol. 22, no. 2, pp. 429â€“441, 2018.\", \"M. Janveja, R. Parmar, S. Dash, J. Pidanic, and G. Trivedi, â€œA low- power co-processor to predict ventricular arrhythmia for wearable healthcare devices,â€IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 32, no. 9, pp. 1672â€“1683, 2024.\", \"L. Chen, Z. Jiang, J. Barker, H. Zhou, F. Schlindwein, W. Nicolson, G. A. Ng, and X. Li, â€œEcgvednet: A variational encoder-decoder network for ecg delineation in morphology variant ecgs,â€IEEE Transac- tions on Biomedical Engineering, vol. 71, no. 7, pp. 2143â€“2153, 2024.\", \"M. Janveja, R. Parmar, and G. Trivedi, â€œMinsc: A vlsi architecture for myocardial infarction stages classifier for wearable healthcare applica- tions,â€IEEE Transactions on Circuits and Systems II: Express Briefs, vol. 70, no. 3, pp. 1159â€“1163, 2023.\", \"A. L. Bui and G. C. Fonarow, â€œHome monitoring for heart failure management,â€Journal of the American College of Cardiology, vol. 59, no. 2, pp. 97â€“104, 2012.\", \"T. Teijeiro, P. F Â´elix, J. Presedo, and D. Castro, â€œHeartbeat classification using abstract features from the abductive interpretation of the ecg,â€ IEEE Journal of Biomedical and Health Informatics, vol. 22, no. 2, pp. 409â€“420, 2018.\", \"T. Ince*, S. Kiranyaz, and M. Gabbouj, â€œA generic and robust sys- tem for automated patient-specific classification of ecg signals,â€IEEE Transactions on Biomedical Engineering, vol. 56, no. 5, pp. 1415â€“1426, 2009.\", \"R. Hoekema, G. Uijen, and A. van Oosterom, â€œGeometrical aspects of the inter-individual variability of multilead ecg recordings,â€ in Computers in Cardiology 1999. Vol.26 (Cat. No.99CH37004), 1999, pp. 499â€“502.\", \"S. Kiranyaz, T. Ince, and M. Gabbouj, â€œReal-time patient-specific ecg classification by 1-d convolutional neural networks,â€IEEE Transactions on Biomedical Engineering, vol. 63, no. 3, pp. 664â€“675, 2016.\", \"Z. Chen, J. Luo, K. Lin, J. Wu, T. Zhu, X. Xiang, and J. Meng, â€œAn energy-efficient ecg processor with weak-strong hybrid classifier for arrhythmia detection,â€IEEE Transactions on Circuits and Systems II: Express Briefs, vol. 65, no. 7, pp. 948â€“952, 2018.\", \"M. A. Sohail, Z. Taufique, S. M. Abubakar, W. Saadeh, and M. A. Bin Altaf, â€œAn ecg processor for the detection of eight cardiac arrhyth- mias with minimum false alarms,â€ in2019 IEEE Biomedical Circuits and Systems Conference (BioCAS), 2019, pp. 1â€“4.\", \"P. Li, Y . Wang, J. He, L. Wang, Y . Tian, T.-s. Zhou, T. Li, and J.-s. Li, â€œHigh-performance personalized heartbeat classification model for long-term ecg signal,â€IEEE Transactions on Biomedical Engineering, vol. 64, no. 1, pp. 78â€“86, 2017.\", \"M. L. Hoang, â€œA review of developments and metrology in machine learning and deep learning for wearable iot devices,â€IEEE Access, vol. 13, pp. 106 035â€“106 054, 2025.\", \"H. Sun, D. Luo, X. Niu, X. Zeng, B. Zheng, H. Liu, and J. Pan, â€œClassification algorithms in automatic diagnosis of ecg arrhythmias: A review,â€IEEE Access, vol. 12, pp. 191 921â€“191 935, 2024.\", \"H. Gao, L. Yan, X. Li, and Z. Zhang, â€œResearch on the recognition of ecg signals based on integrated lstm-gru network,â€ in2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI), 2024, pp. 1088â€“1091.\", \"F. Quir Â´os-Corella, R. Loaiza, R. Matarrita, and E. Meneses, â€œA compre- hensive deep learning pipeline for arrhythmia multi-classification with electrocardiography data,â€ in2024 IEEE 6th International Conference on BioInspired Processing (BIP), 2024, pp. 1â€“6.\", \"S. Saadatnejad, M. Oveisi, and M. Hashemi, â€œLstm-based ecg classifi- cation for continuous monitoring on personal wearable devices,â€IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 2, pp. 515â€“ 523, 2020.\", \"N. Akhtar, J. Fan, A. R. Buzdar, M. Ahmed, and A. Raza, â€œVlsi design of lstm-based ecg classification for continuous cardiac monitoring on wearable devices,â€Electronics Letters, vol. 61, no. 1, p. e70269, 2025.\", \"Arpan, M. Singh, P. Garg, S. Srivastava, and A. K. Saggu, â€œRevolu- tionizing arrhythmia classification: Unleashing the power of machine learning and data amplification for precision healthcare,â€ in2024 Sixth International Conference on Computational Intelligence and Commu- nication Technologies (CCICT), 2024, pp. 516â€“522.\", \"H. T. Al-mousa A, Baniissa J, â€œEnhanced electrocardiogram machine learning-based classification with emphasis on fusion and unknown heartbeat classes,â€DIGITAL HEALTH, vol. 9, 2023.\", \"A. T. Hassan SU, Mohd Zahid MS, â€œClassification of cardiac arrhythmia using a convolutional neural network and bi-directional long short-term memory,â€DIGITAL HEALTH, vol. 8, 2022.\", \"J. Yang, J. Li, K. Lan, A. Wei, H. Wang, S. Huang, and S. Fong, â€œMulti- label attribute selection of arrhythmia for electrocardiogram signals with fusion learning,â€Bioengineering, vol. 9, no. 7, 2022.\", \"D. H. Verspoor K, â€œElectrocardiogram arrhythmia detection with novel signal processing and persistent homology-derived predictors,â€Data Science, vol. 7, no. 1, pp. 29â€“53, 2024.\", \"Q. Xiao, K. Lee, S. A. Mokhtar, I. Ismail, A. L. b. M. Pauzi, Q. Zhang, and P. Y . Lim, â€œDeep learning-based ecg arrhythmia classification: A systematic review,â€Applied Sciences, vol. 13, no. 8, 2023.\", \"P. K. Tyagi, N. Rathore, and D. Agrawal, â€œA review on heartbeat classi- fication for arrhythmia detection using ecg signal processing,â€ in2023 IEEE International Studentsâ€™ Conference on Electrical, Electronics and Computer Science (SCEECS), 2023, pp. 1â€“6.\", \"M. Z. Chao Che, Peiliang Zhang, â€œConstrained transformer network for ecg signal processing and arrhythmia classification,â€BMC Med Inform Decis Mak, vol. 21, no. 184, 2021.\", \"S. Bi, R. Lu, Q. Xu, and P. Zhang, â€œAccurate arrhythmia classifi- cation with multi-branch, multi-head attention temporal convolutional networks,â€Sensors, vol. 24, no. 24, 2024.\", \"L.-H. Wang, Y .-T. Yu, W. Liu, L. Xu, C.-X. Xie, T. Yang, I.-C. Kuo, X.- K. Wang, J. Gao, P.-C. Huang, S.-L. Chen, W.-Y . Chiang, and P. A. R. Abu, â€œThree-heartbeat multilead ecg recognition method for arrhythmia classification,â€IEEE Access, vol. 10, pp. 44 046â€“44 061, 2022.\", \"B. K. Nugraha, Q. D. Amalia, A. S. Safitri, A. Rizal, and H. T. Fauzi, â€œComparison analysis for life-threatening arrhythmia classification from ecg data using machine learning and deep learning methods,â€ in2024 8th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE), 2024, pp. 1â€“6.\", \"E. Essa and X. Xie, â€œMulti-model deep learning ensemble for ecg heartbeat arrhythmia classification,â€ in2020 28th European Signal Processing Conference (EUSIPCO), 2021, pp. 1085â€“1089.\", \"C. Zhang, J. Chang, Y . Guan, Q. Li, X. Wang, and X. Zhang, â€œA low-power ecg processor asic based on an artificial neural network for arrhythmia detection,â€Applied Sciences, vol. 13, no. 17, 2023.\", \"H. T. Tefai, H. Saleh, T. Tekeste, M. Alqutayri, and B. Mohammad, â€œAsic implementation of a pre-trained neural network for ecg feature extraction,â€ in2020 IEEE International Symposium on Circuits and Systems (ISCAS), 2020, pp. 1â€“5.\", \"I. Hoyer, A. Utz, A. L Â¨udecke, H. Kappert, M. Rohr, C. H. Antink, and K. Seidl, â€œDesign of hardware accelerators for optimized and quantized neural networks to detect atrial fibrillation in patch ecg device with risc- v,â€Sensors, vol. 23, no. 5, 2023. www.ijacsa.thesai.org 898|P a g e (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 16, No. 7, 2025\", \"W. Liu, Q. Guo, S. Chen, S. Chang, H. Wang, J. He, and Q. Huang, â€œA fully-mapped and energy-efficient fpga accelerator for dual-function ai-based analysis of ecg,â€Frontiers in Physiology, vol. 14, 2023.\", \"S. K. Varadharajan and V . Nallasamy, â€œImplementation of field pro- grammable gate array (fpga) based distributed arithmetic gated current unit to achieve high ecg diagnosis rate,â€Journal of Nanoelectronics and Optoelectronics, vol. 17, no. 1, pp. 82â€“89, 2022.\", \"A. Gon and A. Mukherjee, â€œDesign and fpga implementation of an efficient architecture for noise removal in ecg signals using lifting-based wavelet denoising,â€ in2023 11th International Symposium on Electronic Systems Devices and Computing (ESDC), vol. 1, 2023, pp. 1â€“6.\", \"J. Guo, W. Li, and H. Huang, â€œAn ecg detection device based on convolutional neural network,â€ in2023 8th International Conference on Intelligent Computing and Signal Processing (ICSP), 2023, pp. 860â€“\", \"[39] M. A. Scrugli, D. Loi, L. Raffo, and P. Meloni, â€œAn adaptive cognitive sensor node for ecg monitoring in the internet of medical things,â€IEEE Access, vol. 10, pp. 1688â€“1705, 2022.\", \"S. Deng, B. L. den Ouden, T. De Coster, C. I. Bart, W. H. Bax, R. H. Poelma, A. A. de Vries, G. Q. Zhang, V . Portero, and D. A. Pijnappels, â€œAn untethered heart rhythm monitoring system with automated ai- based arrhythmia detection for closed-loop experimental application,â€ Advanced Sensor Research, vol. 3, no. 11, p. 2400057, 2024.\", \"Q. Xiao, K. Lee, S. A. Mokhtar, I. Ismail, A. L. b. M. Pauzi, Q. Zhang, and P. Y . Lim, â€œDeep learning-based ecg arrhythmia classification: A systematic review,â€Applied Sciences, vol. 13, no. 8, 2023.\", \"P. K. Tyagi, N. Rathore, and D. Agrawal, â€œA review on heartbeat classi- fication for arrhythmia detection using ecg signal processing,â€ in2023 IEEE International Studentsâ€™ Conference on Electrical, Electronics and Computer Science (SCEECS), 2023, pp. 1â€“6.\", \"M. Z. Chao Che, Peiliang Zhang, â€œConstrained transformer network for ecg signal processing and arrhythmia classification,â€BMC Med Inform Decis Mak, vol. 21, no. 184, 2021.\", \"Hasib-Al-Rashid, N. K. Manjunath, H. Paneliya, M. Hosseini, W. D. Hairston, and T. Mohsenin, â€œA low-power lstm processor for multi- channel brain eeg artifact detection,â€ in2020 21st International Sym- posium on Quality Electronic Design (ISQED), 2020, pp. 105â€“110.\", \"A. R. Buzdar, L. Sun, A. Latif, and A. Buzdar, â€œDistance and speed measurements using fpga and asic on a high data rate system,â€International Journal of Advanced Computer Science and Applications (IJACSA), vol. 6, no. 10, 2015. [Online]. Available: http://dx.doi.org/10.14569/IJACSA.2015.061037\", \"A. R. Buzdar, L. Sun, M. W. Azhar, M. I. Khan, and R. Kashif, â€œArea and energy efficient viterbi accelerator for embedded processor datapaths,â€International Journal of Advanced Computer Science and Applications (IJACSA), vol. 8, no. 3, 2017. [Online]. Available: http://dx.doi.org/10.14569/IJACSA.2017.080355\", \"A. R. Buzdar, A. Latif, L. Sun, and A. Buzdar, â€œFpga prototype implementation of digital hearing aid from software to complete hardware design,â€International Journal of Advanced Computer Science and Applications (IJACSA), vol. 7, no. 1, 2016. [Online]. Available: http://dx.doi.org/10.14569/IJACSA.2016.070188\", \"A. R. Buzdar, L. Sun, R. Kashif, M. W. Azhar, and M. I. Khan, â€œCyclic redundancy checking (crc) accelerator for embedded processor datapaths,â€International Journal of Advanced Computer Science and Applications (IJACSA), vol. 8, no. 2, 2017. [Online]. Available: http://dx.doi.org/10.14569/IJACSA.2017.080242 www.ijacsa.thesai.org 899|P a g e View publication stats\"] \n",
            "\n",
            "You: can you shows these in beautiful manner?\n",
            "\n",
            "AI: Sure, I can help with that! What would you like to do with these citations? I can save them to a DOCX file. What would you like to name the file? \n",
            "\n",
            "You: citations.docx\n",
            "\n",
            "AI: âœ… Summary successfully saved as DOCX.\n",
            "ğŸ“„ File path: /content/Summaries/citations.docx\n",
            "You can now download and share this document. \n",
            "\n",
            "You: exit\n",
            "ğŸ‘‹ Session ended.\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ§  Interactive Research System Ready!\")\n",
        "print(\"Type 'exit' to stop.\\n\")\n",
        "\n",
        "conversation = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"ğŸ‘‹ Session ended.\")\n",
        "        break\n",
        "\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = orchestrator.invoke({\"messages\": conversation})\n",
        "    ai_message = response[\"messages\"][-1]\n",
        "\n",
        "    print(\"\\nAI:\", ai_message.content, \"\\n\")\n",
        "\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": ai_message.content})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLVuj85DaNqI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrEZ21c2aNvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTxS-6SDaNym"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khh-G59xeFlv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
